import glob
import torch
import nibabel as nib
import numpy as np
from scripts.capsnet.model import CapsNetRNN
import os


# ---------- åƒæ•¸ ----------
MODEL_PATH = "model/capsnet/best_capsnet_rnn.pth"
# NII_PATH = "data/raw/AD/sub-14/dswausub-098_S_6601_task-rest_bold.nii.gz"  # è¦æ¨è«–çš„å½±åƒè·¯å¾‘
DEVICE = "cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu")
WINDOW = 5
STRIDE = 3

# ---------- è¼‰å…¥æ¨¡å‹ ----------
model = CapsNetRNN().to(DEVICE)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.eval()

file_list = sorted(glob.glob("data/raw/AD/*/*.nii.gz"))


for nii_path in file_list:
    # ---------- é è™•ç† NIfTI ----------
    nii = nib.load(nii_path)
    data = nii.get_fdata()  # shape: [X, Y, Z, T]
    data = np.transpose(data, (3, 2, 0, 1))  # [T, Z, H, W] â†’ è¦–çª—å–æ¨£

    # Normalize to [0, 1]
    data = (data - np.min(data)) / (np.max(data) - np.min(data) + 1e-8)

    # æ»‘å‹•è¦–çª—ï¼šæ¯å€‹è¦–çª—å¤§å° = WINDOW
    clips = []
    for i in range(0, data.shape[0] - WINDOW + 1, STRIDE):
        clip = data[i : i + WINDOW]  # shape: [window, Z, H, W]
        clips.append(clip)

    inputs = (
        torch.tensor(np.stack(clips), dtype=torch.float32).unsqueeze(1).to(DEVICE)
    )  # [N, 1, W, Z, H, W]
    print(f"ğŸ” Loaded input shape: {inputs.shape}")

    # ---------- æ¨è«– ----------
    with torch.no_grad():
        outputs = model(inputs)
        preds = (outputs > 0.5).float().squeeze().cpu().numpy()

    # ---------- çµæœ ----------
    final_pred = int(np.round(preds.mean()))
    print(f"ğŸ§  Inference Result: {final_pred} (1=AD, 0=CN)")

    # æ¨è«–å¾Œå„²å­˜ activation
    act = model.activations["conv3"]  # [B, C, D, H, W]
    subject_id = os.path.basename(os.path.dirname(nii_path))  # sub-14
    save_path = f"output/group/activations/{subject_id}_conv3.pt"
    torch.save(act.cpu(), save_path)
    print(f"ğŸ’¾ Saved activation to {save_path}")
