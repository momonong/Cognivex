# Cognivex ä½¿ç”¨æ‰‹å†Šèˆ‡å®Œæ•´æ•™å­¸æŒ‡å—

## ğŸ“– ç›®éŒ„

1. [ç³»çµ±æ¦‚è¿°](#ç³»çµ±æ¦‚è¿°)
2. [ç³»çµ±æ¶æ§‹](#ç³»çµ±æ¶æ§‹)
3. [å®‰è£æŒ‡å—](#å®‰è£æŒ‡å—)
4. [ç’°å¢ƒé…ç½®](#ç’°å¢ƒé…ç½®)
5. [è³‡æ–™æº–å‚™](#è³‡æ–™æº–å‚™)
6. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
7. [Web ä»‹é¢ä½¿ç”¨](#web-ä»‹é¢ä½¿ç”¨)
8. [å‘½ä»¤åˆ—æ“ä½œ](#å‘½ä»¤åˆ—æ“ä½œ)
9. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
10. [ç¶­è­·èˆ‡å‡ç´š](#ç¶­è­·èˆ‡å‡ç´š)
11. [é–‹ç™¼è€…æŒ‡å—](#é–‹ç™¼è€…æŒ‡å—)
12. [FAQ å¸¸è¦‹å•é¡Œ](#faq-å¸¸è¦‹å•é¡Œ)

---

## ç³»çµ±æ¦‚è¿°

**Cognivex** æ˜¯ä¸€å€‹åŸºæ–¼å¤šæ™ºèƒ½é«”çš„å¯è§£é‡‹äººå·¥æ™ºæ…§æ¡†æ¶ï¼Œå°ˆé–€ç”¨æ–¼é˜¿èŒ²æµ·é»˜ç—‡çš„åŠŸèƒ½æ€§ç£æŒ¯é€ å½±ï¼ˆfMRIï¼‰åˆ†æã€‚ç³»çµ±æ•´åˆäº†æ·±åº¦å­¸ç¿’æ¨¡å‹ã€çŸ¥è­˜åœ–è­œæ¨ç†ã€ä»¥åŠå¤§å‹èªè¨€æ¨¡å‹ï¼Œæä¾›å®Œæ•´çš„å¾åŸå§‹ fMRI æ•¸æ“šåˆ°è‡¨åºŠå ±å‘Šçš„è‡ªå‹•åŒ–åˆ†ææµç¨‹ã€‚

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- **ğŸ§  æ™ºèƒ½å¤šæ™ºèƒ½é«”ç³»çµ±**: åŸºæ–¼ LangGraph çš„ 7 ç¯€é»åºåˆ—åŒ–è™•ç†ç®¡é“
- **ğŸ” å‹•æ…‹å¯è§£é‡‹å±¤é¸æ“‡**: ä½¿ç”¨ LLM æ™ºèƒ½é¸æ“‡æœ€æœ‰æ„ç¾©çš„ç¥ç¶“ç¶²çµ¡å±¤é€²è¡Œå¯è¦–åŒ–
- **ğŸ”— çŸ¥è­˜åœ–è­œæ•´åˆ**: Neo4j åœ–è³‡æ–™åº«çµåˆ GraphRAG é€²è¡Œèªç¾©æ¨ç†
- **ğŸ“„ é›™èªå ±å‘Šç”Ÿæˆ**: è‡ªå‹•ç”Ÿæˆä¸­è‹±æ–‡è‡¨åºŠåˆ†æå ±å‘Š
- **ğŸ–¥ï¸ äº’å‹•å¼ç¶²é ä»‹é¢**: Streamlit åŸºç¤çš„ç”¨æˆ¶å‹å¥½æ“ä½œä»‹é¢
- **ğŸ”¬ ç§‘å­¸é©—è­‰**: èƒ½è‡ªå‹•è­˜åˆ¥é è¨­æ¨¡å¼ç¶²çµ¡ï¼ˆDMNï¼‰çš„æ´»åŒ–æ¨¡å¼

### ğŸ—ï¸ æŠ€è¡“ç‰¹è‰²

- **æ¨¡å‹ç„¡é—œè¨­è¨ˆ**: æ”¯æ´ CapsNet-RNN å’Œ MCADNNet ç­‰å¤šç¨®æ·±åº¦å­¸ç¿’æ¨¡å‹
- **åº§æ¨™ç³»çµ±ä¿®æ­£**: ä¿®æ­£äº†ç¶­åº¦æ˜ å°„éŒ¯èª¤ï¼Œå¾ 1 å€‹è…¦å€æª¢æ¸¬æå‡è‡³ 54 å€‹è…¦å€
- **å®Œæ•´ç‹€æ…‹ç®¡ç†**: æ™ºèƒ½ UI é–å®šç³»çµ±ï¼Œé˜²æ­¢åˆ†æéç¨‹ä¸­çš„èª¤æ“ä½œ
- **å³æ™‚é€²åº¦è¿½è¹¤**: åˆ†éšæ®µé€²åº¦é¡¯ç¤ºå’Œç‹€æ…‹æ›´æ–°

---

## ç³»çµ±æ¶æ§‹

### ğŸ”„ LangGraph å·¥ä½œæµæ¶æ§‹

```mermaid
graph LR
    A[START] --> B[æ¨ç†ç¯€é»<br/>Inference Node]
    B --> C[ç¯©é¸ç¯€é»<br/>Filtering Node] 
    C --> D[å¾Œè™•ç†ç¯€é»<br/>Post-processing Node]
    D --> E[å¯¦é«”é€£çµç¯€é»<br/>Entity Linking Node]
    E --> F[çŸ¥è­˜æ¨ç†ç¯€é»<br/>Knowledge Reasoning Node]
    F --> G[å½±åƒè§£é‡‹ç¯€é»<br/>Image Explanation Node]
    G --> H[å ±å‘Šç”Ÿæˆç¯€é»<br/>Report Generation Node]
    H --> I[END]
  
    style A fill:#f0f0f0
    style B fill:#e1f5fe
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#fff3e0
    style F fill:#fce4ec
    style G fill:#f1f8e9
    style H fill:#e3f2fd
    style I fill:#f0f0f0
```

### ğŸ¢ ç³»çµ±çµ„ä»¶æ¶æ§‹

```
semantic-KG/
â”œâ”€â”€ app/                      # æ–°ç‰ˆ LangGraph åˆ†æç®¡é“
â”‚   â”œâ”€â”€ agents/               # ç®¡é“ç¯€é»å¯¦ç¾
â”‚   â”‚   â”œâ”€â”€ inference.py      # æ¨¡å‹æ¨ç†å’Œåˆ†é¡
â”‚   â”‚   â”œâ”€â”€ filtering.py      # å‹•æ…‹å±¤ç¯©é¸
â”‚   â”‚   â”œâ”€â”€ postprocessing.py # æ´»åŒ–åœ–è™•ç†
â”‚   â”‚   â”œâ”€â”€ entity_linking.py # è…¦å€å¯¦é«”é€£çµ
â”‚   â”‚   â”œâ”€â”€ knowledge_reasoning.py # Neo4j çŸ¥è­˜æ•´åˆ
â”‚   â”‚   â”œâ”€â”€ image_explainer.py # è¦–è¦ºåˆ†æ
â”‚   â”‚   â””â”€â”€ report_generator.py # è‡¨åºŠå ±å‘Šåˆæˆ
â”‚   â”œâ”€â”€ core/                 # æ ¸å¿ƒè™•ç†å·¥å…·
â”‚   â”‚   â”œâ”€â”€ fmri_processing/  # fMRI åˆ†æç®¡é“
â”‚   â”‚   â”œâ”€â”€ knowledge_graph/  # çŸ¥è­˜åœ–è­œæŸ¥è©¢å·¥å…·
â”‚   â”‚   â””â”€â”€ vision/           # å½±åƒè§£é‡‹å·¥å…·
â”‚   â”œâ”€â”€ graph/                # LangGraph å·¥ä½œæµå®šç¾©
â”‚   â”‚   â”œâ”€â”€ state.py          # AgentState ç‹€æ…‹æ¶æ§‹
â”‚   â”‚   â””â”€â”€ workflow.py       # å®Œæ•´ç®¡é“å·¥ä½œæµ
â”‚   â””â”€â”€ services/             # å¤–éƒ¨æœå‹™é€£æ¥å™¨
â”‚       â”œâ”€â”€ llm_providers/    # æ¨¡çµ„åŒ– LLM ä¾›æ‡‰å•†
â”‚       â”‚   â”œâ”€â”€ __init__.py   # çµ±ä¸€å‘¼å«ä»‹é¢
â”‚       â”‚   â”œâ”€â”€ gemini.py     # Google Vertex AI Gemini
â”‚       â”‚   â”œâ”€â”€ bedrock.py    # AWS Bedrock Claude
â”‚       â”‚   â””â”€â”€ ollama.py     # Ollama æœ¬åœ°æ¨ç†
â”‚       â””â”€â”€ neo4j_connector.py # Neo4j è³‡æ–™åº«ä»‹é¢
â”œâ”€â”€ agents/                   # èˆŠç‰ˆ Google ADK ç³»çµ±ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
â”œâ”€â”€ data/                     # fMRI è³‡æ–™é›† (AD/CN å—è©¦è€…)
â”œâ”€â”€ model/                    # è¨“ç·´å®Œæˆçš„ç¥ç¶“ç¶²çµ¡æ¬Šé‡
â”œâ”€â”€ scripts/                  # è³‡æ–™è™•ç†å’Œè¨“ç·´è…³æœ¬
â”œâ”€â”€ graphql/                  # Neo4j çŸ¥è­˜åœ–è­œ
â””â”€â”€ app.py                   # Streamlit ç¶²é ä»‹é¢
```

### ğŸ“Š è³‡æ–™æµæ¶æ§‹

```mermaid
flowchart LR
    A[fMRI æƒæ<br/>.nii.gz] --> B[æ·±åº¦å­¸ç¿’<br/>CapsNet/MCADNNet]
    B --> C[å±¤ç¯©é¸<br/>LLM-based]
    C --> D[å¾Œè™•ç†<br/>NIfTI]
    D --> E[å¯¦é«”é€£çµ<br/>è…¦å€è­˜åˆ¥]
    E --> F[çŸ¥è­˜åœ–è­œ<br/>Neo4j]
    F --> G[å¤šæ¨¡æ…‹åˆ†æ<br/>LLM Providers]
    G --> H[æœ€çµ‚å ±å‘Š<br/>ä¸­è‹±æ–‡]
  
    B --> B1[åˆ†é¡çµæœ<br/>AD/CN]
    D --> D1[æ´»åŒ–åœ–]
    F --> F1[è…¦å€çŸ¥è­˜]
    G --> G1[Gemini/Bedrock/Ollama]
  
    style A fill:#e3f2fd
    style B fill:#e1f5fe
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#fff3e0
    style F fill:#fce4ec
    style G fill:#f1f8e9
    style H fill:#e3f2fd
    style G1 fill:#fff9c4
```

### ğŸ¤– LLM ä¾›æ‡‰å•†æ¶æ§‹

```mermaid
flowchart TD
    A[çµ±ä¸€ LLM ä»‹é¢] --> B[llm_response\nç´”æ–‡å­—]
    A --> C[llm_image_response\nå¤šæ¨¡æ…‹]
    
    B --> D[Gemini Provider]
    B --> E[Bedrock Provider]
    B --> F[Ollama Provider]
    
    C --> D
    C --> E
    
    D --> D1[Vertex AI<br/>gemini-1.5-flash]
    E --> E1[AWS Bedrock<br/>Claude Haiku]
    F --> F1[æœ¬åœ°æ¨¡å‹<br/>gpt-oss-20b]
    
    style A fill:#e1f5fe
    style D fill:#e8f5e8
    style E fill:#fff3e0
    style F fill:#fce4ec
```

---

## å®‰è£æŒ‡å—

### ğŸ“‹ ç³»çµ±éœ€æ±‚

#### ç¡¬é«”éœ€æ±‚

- **GPU**: NVIDIA GPU é…å‚™ CUDA æ”¯æ´ï¼ˆæ¨è–¦ç”¨æ–¼è¨“ç·´/æ¨ç†ï¼‰
- **è¨˜æ†¶é«”**: 16GB+ RAM ç”¨æ–¼è™•ç† fMRI è³‡æ–™
- **å„²å­˜ç©ºé–“**: 50GB+ ç”¨æ–¼è³‡æ–™é›†å’Œæ¨¡å‹æ¬Šé‡
- **Neo4j è³‡æ–™åº«**: é‹è¡Œä¸­çš„ Neo4j è³‡æ–™åº«å¯¦ä¾‹ï¼ˆæœ¬åœ°æˆ–é ç«¯ï¼‰

#### è»Ÿé«”éœ€æ±‚

- **ä½œæ¥­ç³»çµ±**: Ubuntu 20.04+ / macOS 12+ / Windows 11
- **Python**: 3.11+ (é…ç½®ç‚º `>=3.11,<3.14`)
- **CUDA**: CUDA 11.8+ (ç”¨æ–¼ GPU åŠ é€Ÿ)
- **Docker**: Docker Desktop (å¯é¸ï¼Œç”¨æ–¼ Neo4j)

### ğŸš€ å®‰è£æ­¥é©Ÿ

#### æ­¥é©Ÿ 1: ä¸‹è¼‰å°ˆæ¡ˆ

```bash
# è¤‡è£½å°ˆæ¡ˆåº«
git clone [repository-url]
cd semantic-KG

# æˆ–è€…å¾ç¾æœ‰å°ˆæ¡ˆç›®éŒ„é–‹å§‹
cd /path/to/semantic-KG
```

#### æ­¥é©Ÿ 2: Python ç’°å¢ƒè¨­ç½®

```bash
# å»ºè­°ä½¿ç”¨ Poetryï¼ˆæ¨è–¦æ–¹å¼ï¼‰
# å®‰è£ Poetry
curl -sSL https://install.python-poetry.org | python3 -

# å®‰è£å°ˆæ¡ˆç›¸ä¾å¥—ä»¶
poetry install

# æ¿€æ´»è™›æ“¬ç’°å¢ƒ
poetry shell
```

**æˆ–è€…ä½¿ç”¨ pip:**

```bash
# å‰µå»ºè™›æ“¬ç’°å¢ƒ
python3 -m venv .venv

# æ¿€æ´»è™›æ“¬ç’°å¢ƒ
# Linux/macOS:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate

# å®‰è£ç›¸ä¾å¥—ä»¶
pip install -r requirements.txt
```

#### æ­¥é©Ÿ 3: PyTorch å’Œ CUDA è¨­ç½®

```bash
# æ¨è–¦çš„ CUDA PyTorch å®‰è£æ–¹å¼
python -m pip install light-the-torch
python -m light_the_torch install --upgrade torch torchaudio torchvision

# æˆ–ä½¿ç”¨ Poetry ä»»å‹™
poetry run poe autoinstall-torch-cuda

# é©—è­‰ CUDA å®‰è£
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

#### æ­¥é©Ÿ 4: Neo4j è³‡æ–™åº«è¨­ç½®

#### æ­¥é©Ÿ 4: LLM æœå‹™è¨­å®š

**Google Vertex AI è¨­å®šï¼ˆæ¨è–¦ï¼‰**

```bash
# ä¸‹è¼‰ GCP æœå‹™å¸³è™Ÿé‡‘é‘°ï¼ˆJSON æª”æ¡ˆï¼‰
# æ”¾ç½®åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼šgcp-service-account.json

# è¨­å®šç’°å¢ƒè®Šæ•¸
export GOOGLE_APPLICATION_CREDENTIALS="./gcp-service-account.json"
export GOOGLE_CLOUD_PROJECT="your-project-id"
export GOOGLE_CLOUD_LOCATION="us-central1"

# é©—è­‰ Vertex AI é€£æ¥
python -c "from app.services.llm_providers.gemini import handle_chat; print('Vertex AI connected')"
```

**AWS Bedrock è¨­å®šï¼ˆå¯é¸ï¼‰**

```bash
# è¨­å®š AWS èªè­‰
export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export AWS_DEFAULT_REGION="us-east-1"

# å®‰è£ AWS CLI
pip install boto3

# é©—è­‰ Bedrock é€£æ¥
python -c "from app.services.llm_providers.bedrock import handle_text; print('Bedrock ready')"
```

**Ollama æœ¬åœ°è¨­å®šï¼ˆå¯é¸ï¼‰**

```bash
# å®‰è£ Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# å•“å‹• Ollama æœå‹™
ollama serve

# ä¸‹è¼‰æ¨¡å‹
ollama pull llama3.2
ollama pull qwen2.5:14b

# é©—è­‰é€£æ¥
curl http://localhost:11434/api/tags
```

#### æ­¥é©Ÿ 5: Neo4j è³‡æ–™åº«è¨­ç½®

**é¸é … A: ä½¿ç”¨ Dockerï¼ˆæ¨è–¦ï¼‰**

```bash
# å•Ÿå‹• Neo4j å®¹å™¨
docker run -d \
    --name neo4j-fmri \
    -p 7474:7474 -p 7687:7687 \
    -e NEO4J_AUTH=neo4j/your_password \
    -v neo4j_data:/data \
    neo4j:5.28.2

# é©—è­‰é€£æ¥
docker logs neo4j-fmri
```

**é¸é … B: æœ¬åœ°å®‰è£**

```bash
# Ubuntu/Debian
wget -O - https://debian.neo4j.com/neotechnology.gpg.key | sudo apt-key add -
echo 'deb https://debian.neo4j.com stable 5' | sudo tee -a /etc/apt/sources.list.d/neo4j.list
sudo apt-get update
sudo apt-get install neo4j

# å•Ÿå‹•æœå‹™
sudo systemctl enable neo4j
sudo systemctl start neo4j
sudo systemctl status neo4j
```

#### æ­¥é©Ÿ 6: ç’°å¢ƒè®Šæ•¸é…ç½®

å‰µå»ºå°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ `.env` æª”æ¡ˆï¼š

```bash
# .env æª”æ¡ˆé…ç½®
# Neo4j çŸ¥è­˜åœ–è­œè¨­å®š
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# ä¸»è¦ LLM ä¾›æ‡‰å•†ï¼šGoogle Vertex AI
GOOGLE_CLOUD_PROJECT=your_gcp_project_id
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=./gcp-service-account.json
GOOGLE_GENAI_USE_VERTEXAI=1

# å‚™ç”¨ LLM ä¾›æ‡‰å•†ï¼šAWS Bedrock
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_DEFAULT_REGION=us-east-1

# æœ¬åœ° LLM ä¾›æ‡‰å•†ï¼šOllama
OLLAMA_BASE_URL=http://localhost:11434

# å¯é¸ï¼šé›²ç«¯éƒ¨ç½²è¨­å®š
PROJECT_ID=your_gcp_project_id
LOCATION=your_gcp_location
BUCKET_ID=your_gcp_bucket
```

### ğŸ¤– LLM ä¾›æ‡‰å•†é¸æ“‡æŒ‡å—

Cognivex æ”¯æ´å¤šç¨® LLM ä¾›æ‡‰å•†ï¼Œæ‚¨å¯ä»¥æ ¹æ“šéœ€æ±‚é¸æ“‡ï¼š

#### 1. **Google Vertex AI Gemini**ï¼ˆæ¨è–¦ï¼‰
- **å„ªé»**ï¼šå„ªç•°çš„å¤šæ¨¡æ…‹èƒ½åŠ›ï¼Œç‰¹åˆ¥é©åˆå½±åƒåˆ†æ
- **æ”¯æ´æ¨¡å‹**ï¼š`gemini-1.5-flash`ã€`gemini-1.5-pro`
- **é©ç”¨å ´æ™¯**ï¼šç”Ÿç”¢ç’°å¢ƒã€éœ€è¦å¤šæ¨¡æ…‹åˆ†æ
- **æˆæœ¬**ï¼šä¸­ç­‰ï¼ˆæŒ‰ä½¿ç”¨é‡è¨ˆè²»ï¼‰

#### 2. **AWS Bedrock Claude**ï¼ˆå‚™ç”¨ï¼‰
- **å„ªé»**ï¼šå„ªç•°çš„æ–‡æœ¬ç†è§£å’Œç”Ÿæˆèƒ½åŠ›
- **æ”¯æ´æ¨¡å‹**ï¼š`anthropic.claude-haiku-4-5-20251001-v1:0`
- **é©ç”¨å ´æ™¯**ï¼šéœ€è¦é«˜å“è³ªæ–‡æœ¬ç”Ÿæˆã€ä¼æ¥­ç’°å¢ƒ
- **æˆæœ¬**ï¼šä½ï¼ˆHaiku æ¨¡å‹ç›¸å°ä¾¿å®œï¼‰

#### 3. **Ollama æœ¬åœ°æ¨ç†**ï¼ˆé–‹ç™¼/é›¢ç·šï¼‰
- **å„ªé»**ï¼šå®Œå…¨æœ¬åœ°åŒ–ã€ç„¡ç¶²è·¯æˆæœ¬ã€æ•¸æ“šéš±ç§
- **æ”¯æ´æ¨¡å‹**ï¼š`llama3.2`ã€`qwen2.5:14b`ã€å…¶ä»–é–‹æºæ¨¡å‹
- **é©ç”¨å ´æ™¯**ï¼šé–‹ç™¼æ¸¬è©¦ã€é›¢ç·šç’°å¢ƒã€æ•¸æ“šç›§æ¬§åš´æ ¼
- **æˆæœ¬**ï¼šç„¡ï¼ˆä½†éœ€è¦æœ¬åœ° GPU è³‡æºï¼‰

---

## ç’°å¢ƒé…ç½®

### ğŸ”§ çŸ¥è­˜åœ–è­œå»ºç½®

å»ºç½® Neo4j çŸ¥è­˜åœ–è­œæ˜¯ç³»çµ±é‹è¡Œçš„å¿…è¦æ­¥é©Ÿï¼š

```bash
# å»ºç½® Neo4j åœ–è³‡æ–™åº«
python -m tools.build_neo4j

# é©—è­‰é€£æ¥ä¸¦æ¸¬è©¦æŸ¥è©¢
python -c "from app.services.neo4j_connector import Neo4jConnector; client = Neo4jConnector(); print('Neo4j connected successfully!')"

# æª¢æŸ¥åœ–è³‡æ–™çµ±è¨ˆ
python -m scripts.capsnet.build_kg  # æª¢è¦–çŸ¥è­˜åœ–è­œçµ±è¨ˆè³‡è¨Š
```

### ğŸ“‚ è³‡æ–™ç›®éŒ„çµæ§‹è¨­ç½®

å‰µå»ºå¿…è¦çš„è³‡æ–™ç›®éŒ„çµæ§‹ï¼š

```bash
# å‰µå»ºè³‡æ–™ç›®éŒ„
mkdir -p data/{raw,processed,slices}
mkdir -p data/raw/{AD,CN}
mkdir -p model/{capsnet,macadnnet}
mkdir -p output/{activations,brain_maps,visualizations}
mkdir -p graphql/visualizations

# è¨­ç½®æ¬Šé™
chmod -R 755 data/ model/ output/ graphql/
```

### ğŸ§ª ç³»çµ±é©—è­‰æ¸¬è©¦

é‹è¡Œç³»çµ±çµ„ä»¶æ¸¬è©¦ç¢ºä¿é…ç½®æ­£ç¢ºï¼š

```bash
# æ¸¬è©¦ Neo4j é€£æ¥
python -m tests.brain_region

# æ¸¬è©¦æ¨¡å‹è¼‰å…¥
python -m tests.model_info

# æ¸¬è©¦ fMRI è³‡æ–™è¼‰å…¥
python -m tests.nii_check

# æ¸¬è©¦ LLM æœå‹™é€£æ¥
python -m tests.image_explain

# æ¸¬è©¦å¤šç¨® LLM ä¾›æ‡‰å•†
python -c "from app.services.llm_providers import llm_response; print(llm_response('Hello', llm_provider='gemini'))"
python -c "from app.services.llm_providers import llm_response; print(llm_response('Hello', llm_provider='aws_bedrock'))" 
python -c "from app.services.llm_providers import llm_response; print(llm_response('Hello', llm_provider='gpt-oss-20b', model='llama3.2'))"

# æ¸¬è©¦å®Œæ•´ç®¡é“ï¼ˆä½¿ç”¨ç¯„ä¾‹è³‡æ–™ï¼‰
python -m tests.vertex
```

---

## è³‡æ–™æº–å‚™

### ğŸ“¥ ä¸‹è¼‰å¿…è¦æª”æ¡ˆ

#### 1. fMRI è³‡æ–™é›†

å¾é›²ç«¯å„²å­˜ä¸‹è¼‰é è™•ç†çš„ fMRI è³‡æ–™ï¼š

```bash
# ä¸‹è¼‰é€£çµï¼ˆéœ€è¦æ›¿æ›ç‚ºå¯¦éš›é€£çµï¼‰
# https://u.pcloud.link/publink/show?code=kZEgL15ZhlezDWqfUEY3MkFwUK9Gtui7w0T7

# è§£å£“ç¸®åˆ°æ­£ç¢ºä½ç½®
unzip data.zip
cp -r extracted_data/raw/* data/raw/

# é©—è­‰è³‡æ–™çµæ§‹
ls -la data/raw/AD/
ls -la data/raw/CN/
```

#### 2. é è¨“ç·´æ¨¡å‹æ¬Šé‡

ä¸‹è¼‰é è¨“ç·´çš„æ¨¡å‹æ¬Šé‡ï¼š

```bash
# ä¸‹è¼‰æ¨¡å‹æ¬Šé‡ï¼ˆéœ€è¦æ›¿æ›ç‚ºå¯¦éš›é€£çµï¼‰
# https://u.pcloud.link/publink/show?code=kZ7gL15ZoCYrxwMqwwQmmBYDWfDmuy2GB4Ly

# æ”¾ç½®æ¨¡å‹æª”æ¡ˆ
cp best_capsnet_rnn.pth model/capsnet/
cp mcadnnet_weights.pth model/macadnnet/

# é©—è­‰æ¨¡å‹æª”æ¡ˆ
ls -la model/capsnet/
ls -la model/macadnnet/
```

### ğŸ“ è³‡æ–™ç›®éŒ„çµæ§‹

å®Œæ•´çš„è³‡æ–™ç›®éŒ„çµæ§‹æ‡‰å¦‚ä¸‹æ‰€ç¤ºï¼š

```
data/
â”œâ”€â”€ raw/                    # åŸå§‹ fMRI è³‡æ–™
â”‚   â”œâ”€â”€ AD/                # é˜¿èŒ²æµ·é»˜ç—‡æ‚£è€…
â”‚   â”‚   â”œâ”€â”€ sub-01/        # å—è©¦è€… 1
â”‚   â”‚   â”‚   â””â”€â”€ dswausub-xxx_task-rest_bold.nii.gz
â”‚   â”‚   â”œâ”€â”€ sub-02/        # å—è©¦è€… 2
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ CN/                # å¥åº·å°ç…§çµ„
â”‚       â”œâ”€â”€ sub-01/
â”‚       â”‚   â””â”€â”€ dswausub-xxx_task-rest_bold.nii.gz
â”‚       â”œâ”€â”€ sub-02/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ processed/             # è™•ç†ä¸­é–“çµæœ
â””â”€â”€ slices/               # 2D åˆ‡ç‰‡å½±åƒï¼ˆå¦‚ä½¿ç”¨åˆ‡ç‰‡è¨“ç·´ï¼‰

model/
â”œâ”€â”€ capsnet/               # CapsNet-RNN æ¨¡å‹æ¬Šé‡
â”‚   â””â”€â”€ best_capsnet_rnn.pth
â””â”€â”€ macadnnet/            # MCADNNet æ¨¡å‹æ¬Šé‡
    â””â”€â”€ best_model.pth

output/                    # åˆ†æçµæœ
â”œâ”€â”€ activations/           # ç¥ç¶“ç¶²çµ¡æ´»åŒ–åœ–
â”œâ”€â”€ brain_maps/           # è…¦å€åˆ†æçµæœ
â””â”€â”€ visualizations/       # ç”Ÿæˆçš„åœ–è¡¨å’Œç†±åŠ›åœ–

graphql/                  # çŸ¥è­˜åœ–è­œè³‡æ–™
â”œâ”€â”€ semantic_graph.graphml
â”œâ”€â”€ nodes.csv
â”œâ”€â”€ edges.csv
â””â”€â”€ visualizations/
```

### ğŸ” è³‡æ–™é©—è­‰

é©—è­‰è³‡æ–™å®Œæ•´æ€§å’Œæ ¼å¼ï¼š

```bash
# æª¢æŸ¥ fMRI æª”æ¡ˆæ ¼å¼å’Œå®Œæ•´æ€§
python -m scripts.group.check_map

# é©—è­‰æ¨¡å‹æ¬Šé‡å¯è¼‰å…¥æ€§
python -m tests.model_info

# æª¢æŸ¥è³‡æ–™é›†çµ±è¨ˆè³‡è¨Š
find data/raw/AD -name "*.nii.gz" | wc -l
find data/raw/CN -name "*.nii.gz" | wc -l
```

---

## ä½¿ç”¨æŒ‡å—

### ğŸŒ ä¸»è¦ä½¿ç”¨æ–¹å¼

Cognivex æä¾›å…©ç¨®ä¸»è¦çš„ä½¿ç”¨æ–¹å¼ï¼š

1. **Web ä»‹é¢**ï¼ˆæ¨è–¦æ–°ç”¨æˆ¶ï¼‰: é€é Streamlit åœ–å½¢åŒ–ä»‹é¢
2. **å‘½ä»¤åˆ—ä»‹é¢**ï¼ˆé©åˆæ‰¹æ¬¡è™•ç†ï¼‰: ç›´æ¥åŸ·è¡Œ Python è…³æœ¬

### ğŸ–¥ï¸ Web ä»‹é¢å¿«é€Ÿé–‹å§‹

æœ€ç°¡å–®çš„ä½¿ç”¨æ–¹å¼æ˜¯é€é Web ä»‹é¢ï¼š

```bash
# å•Ÿå‹• Web æ‡‰ç”¨ç¨‹å¼
streamlit run app.py

# æˆ–ä½¿ç”¨ Poetry
poetry run streamlit run app.py

# æ‡‰ç”¨ç¨‹å¼å°‡åœ¨ http://localhost:8501 å•Ÿå‹•
```

### âš¡ å¿«é€Ÿåˆ†ææµç¨‹

å°æ–¼æ€¥æ–¼çœ‹åˆ°çµæœçš„ç”¨æˆ¶ï¼Œä»¥ä¸‹æ˜¯æœ€å¿«çš„åˆ†ææµç¨‹ï¼š

1. **ç¢ºä¿ç’°å¢ƒæº–å‚™å°±ç·’**:

   - Neo4j è³‡æ–™åº«é‹è¡Œä¸­
   - `.env` æª”æ¡ˆé…ç½®æ­£ç¢º
   - fMRI è³‡æ–™å’Œæ¨¡å‹æ¬Šé‡å·²ä¸‹è¼‰
2. **å•Ÿå‹• Web ä»‹é¢**:

   ```bash
   streamlit run app.py
   ```
3. **åœ¨ Web ä»‹é¢ä¸­**:

   - é¸æ“‡å—è©¦è€…ï¼ˆä¾‹å¦‚ `sub-01`ï¼‰
   - é¸æ“‡æ¨¡å‹ï¼ˆæ¨è–¦ `CapsNet`ï¼‰
   - é»æ“Š "Start Analysis"
   - ç­‰å¾…åˆ†æå®Œæˆï¼ˆç´„ 3-5 åˆ†é˜ï¼‰
4. **æª¢è¦–çµæœ**:

   - æŸ¥çœ‹è…¦å€æ´»åŒ–åœ–
   - é–±è®€ä¸­è‹±æ–‡è‡¨åºŠå ±å‘Š
   - ä½¿ç”¨äº’å‹•å¼è…¦éƒ¨æª¢è¦–å™¨

---

## Web ä»‹é¢ä½¿ç”¨

### ğŸ–±ï¸ ä»‹é¢æ¦‚è¦½

Streamlit Web ä»‹é¢åŒ…å«ä»¥ä¸‹ä¸»è¦å€åŸŸï¼š

#### å´é‚Šæ¬„æ§åˆ¶å€

- **å—è©¦è€…é¸æ“‡å™¨**: å¾å¯ç”¨çš„ fMRI è³‡æ–™ä¸­é¸æ“‡å—è©¦è€…
- **æ¨¡å‹é¸æ“‡å™¨**: é¸æ“‡åˆ†ææ¨¡å‹ï¼ˆCapsNet / MCADNNetï¼‰
- **åˆ†ææ§åˆ¶æŒ‰éˆ•**: é–‹å§‹åˆ†æå’Œç·Šæ€¥åœæ­¢åŠŸèƒ½
- **æ¨¡å‹è³‡è¨Šé¡¯ç¤º**: é¡¯ç¤ºé¸ä¸­æ¨¡å‹çš„è©³ç´°è³‡è¨Š

#### ä¸»è¦é¡¯ç¤ºå€åŸŸ

- **é€²åº¦è¿½è¹¤**: å³æ™‚åˆ†æé€²åº¦å’Œç‹€æ…‹æ›´æ–°
- **çµæœå±•ç¤º**: åˆ†æå®Œæˆå¾Œçš„çµæœé¡¯ç¤ºå€åŸŸ
- **äº’å‹•å¼æª¢è¦–å™¨**: å¯å±•é–‹çš„ 3D è…¦éƒ¨å½±åƒæª¢è¦–å™¨
- **å ±å‘Šåˆ†é **: ä¸­è‹±æ–‡è‡¨åºŠå ±å‘Šä¸¦æ’é¡¯ç¤º

### ğŸ“± ä½¿ç”¨æ“ä½œæµç¨‹

#### æ­¥é©Ÿ 1: å•Ÿå‹•æ‡‰ç”¨

```bash
# é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd /path/to/semantic-KG

# å•Ÿå‹•æ‡‰ç”¨
streamlit run app.py
```

ç€è¦½å™¨å°‡è‡ªå‹•æ‰“é–‹æˆ–æ‰‹å‹•è¨ªå• `http://localhost:8501`

#### æ­¥é©Ÿ 2: é¸æ“‡åˆ†æåƒæ•¸

1. **é¸æ“‡å—è©¦è€…**:

   - åœ¨å´é‚Šæ¬„çš„ "Select Subject" ä¸‹æ‹‰é¸å–®ä¸­é¸æ“‡
   - ç³»çµ±æœƒè‡ªå‹•é¡¯ç¤ºå—è©¦è€…çš„çœŸå¯¦æ¨™ç±¤ï¼ˆAD æˆ– CNï¼‰
   - å—è©¦è€… ID æ ¼å¼é€šå¸¸ç‚º `sub-01`, `sub-02` ç­‰
2. **é¸æ“‡æ¨ç†æ¨¡å‹**:

   - **CapsNet**: 3D è† å›Šç¶²çµ¡ï¼Œé©åˆè¤‡é›œ 3D fMRI æ¨¡å¼
   - **MCADNNet**: 2D å·ç©ç¥ç¶“ç¶²çµ¡ï¼Œè¨ˆç®—æ•ˆç‡é«˜
3. **æª¢è¦–æ¨¡å‹è³‡è¨Š**:

   - ç³»çµ±æœƒé¡¯ç¤ºé¸ä¸­æ¨¡å‹çš„é¡å‹ã€æè¿°å’Œé©ç”¨å ´æ™¯

#### æ­¥é©Ÿ 3: é–‹å§‹åˆ†æ

1. é»æ“Š "Start Analysis" æŒ‰éˆ•
2. ç³»çµ±æœƒé€²å…¥åˆ†ææ¨¡å¼:
   - æ‰€æœ‰æ§åˆ¶é …è¢«é–å®šï¼Œé˜²æ­¢èª¤æ“ä½œ
   - é¡¯ç¤ºå³æ™‚é€²åº¦æ¢å’Œç‹€æ…‹è¨Šæ¯
   - å„éšæ®µé€²åº¦æ›´æ–°ï¼š
     - æº–å‚™åˆ†æ...ï¼ˆ10%ï¼‰
     - è¼‰å…¥è³‡æ–™æª”æ¡ˆ...ï¼ˆ20%ï¼‰
     - é–‹å§‹å¤§è…¦åˆ†æå·¥ä½œæµ...ï¼ˆ30%ï¼‰
     - é‹è¡Œ AI åˆ†æç®¡é“...ï¼ˆ50%ï¼‰
     - å®Œæˆçµæœ...ï¼ˆ90%ï¼‰
     - åˆ†ææˆåŠŸå®Œæˆï¼ï¼ˆ100%ï¼‰

#### æ­¥é©Ÿ 4: æª¢è¦–åˆ†æçµæœ

åˆ†æå®Œæˆå¾Œï¼Œçµæœå€åŸŸå°‡é¡¯ç¤ºï¼š

1. **è…¦å€æ´»åŒ–åœ–**:

   - é«˜è§£æåº¦çš„å¤§è…¦æ´»åŒ–ç†±åŠ›åœ–
   - ç–ŠåŠ åœ¨æ¨™æº–è…¦éƒ¨è§£å‰–çµæ§‹ä¸Š
   - é¡¯ç¤º fMRI åˆ†æä¸­æª¢æ¸¬åˆ°çš„æ´»åŒ–å€åŸŸ
2. **é æ¸¬é©—è­‰**:

   - ä¸¦æ’é¡¯ç¤ºçœŸå¯¦æ¨™ç±¤å’Œæ¨¡å‹é æ¸¬
   - ç¶ è‰²å‹¾è™Ÿï¼ˆâœ…ï¼‰è¡¨ç¤ºé æ¸¬æ­£ç¢º
   - ç´…è‰²å‰è™Ÿï¼ˆâŒï¼‰è¡¨ç¤ºé æ¸¬éŒ¯èª¤
3. **äº’å‹•å¼ fMRI æª¢è¦–å™¨**:

   - å¯å±•é–‹çš„å€åŸŸï¼Œé¡¯ç¤ºåŸå§‹ fMRI æƒæ
   - æ™‚é–“é»æ»‘æ¡¿ï¼šé¸æ“‡ä¸åŒçš„ fMRI æ™‚é–“é«”ç©
   - 3D è…¦éƒ¨åˆ‡ç‰‡æª¢è¦–å™¨ï¼Œæ”¯æ´å¤šæ–¹å‘æª¢è¦–
4. **é›™èªè‡¨åºŠå ±å‘Š**:

   - **English Report**: å®Œæ•´çš„è‹±æ–‡è‡¨åºŠåˆ†æå ±å‘Š
   - **ä¸­æ–‡å ±å‘Š**: ç¹é«”ä¸­æ–‡è‡¨åºŠåˆ†æå ±å‘Š
   - å ±å‘ŠåŒ…å«ï¼š
     - åˆ†é¡çµæœå’Œä¿¡å¿ƒåº¦
     - æª¢æ¸¬åˆ°çš„æ´»åŒ–è…¦å€åŠå…¶åŠŸèƒ½
     - èˆ‡é˜¿èŒ²æµ·é»˜ç—‡ç›¸é—œçš„ç—…ç†å­¸è§£é‡‹
     - è‡¨åºŠå»ºè­°å’Œé€²ä¸€æ­¥æª¢æŸ¥å»ºè­°

### ğŸ›¡ï¸ å®‰å…¨åŠŸèƒ½

#### æ™ºèƒ½ç‹€æ…‹ç®¡ç†

- **åˆ†ææœŸé–“é–å®š**: åˆ†æé‹è¡Œæ™‚ï¼Œæ‰€æœ‰æ§åˆ¶é …è‡ªå‹•ç¦ç”¨
- **åƒæ•¸è®Šæ›´æª¢æ¸¬**: æ”¹è®Šå—è©¦è€…æˆ–æ¨¡å‹æœƒè‡ªå‹•é‡ç½®çµæœ
- **ç·Šæ€¥åœæ­¢**: æä¾› "Force Stop Analysis" æŒ‰éˆ•ä¸­æ–·é•·æ™‚é–“é‹è¡Œçš„åˆ†æ

#### éŒ¯èª¤è™•ç†

- æª”æ¡ˆç¼ºå¤±è‡ªå‹•æª¢æ¸¬å’ŒéŒ¯èª¤æç¤º
- ç¶²çµ¡é€£æ¥å•é¡Œçš„å‹å¥½éŒ¯èª¤è¨Šæ¯
- åˆ†æå¤±æ•—æ™‚çš„è‡ªå‹•ç‹€æ…‹æ¢å¾©

### ğŸ›ï¸ é«˜ç´šåŠŸèƒ½

#### äº’å‹•å¼è…¦éƒ¨æª¢è¦–å™¨

- **4D fMRI æ”¯æ´**: è‡ªå‹•æª¢æ¸¬ä¸¦è™•ç† 4D fMRI è³‡æ–™
- **æ™‚é–“è»¸å°èˆª**: æ»‘æ¡¿æ§åˆ¶æª¢è¦–ä¸åŒæ™‚é–“é»çš„è…¦éƒ¨æ´»å‹•
- **å¤šè¦–è§’æª¢è¦–**: æ”¯æ´è»¸ç‹€é¢ã€å† ç‹€é¢ã€çŸ¢ç‹€é¢æª¢è¦–
- **é¡è‰²æ˜ å°„**: å¯èª¿æ•´çš„é¡è‰²å°æ¯”å’Œé–¾å€¼è¨­å®š

#### çµæœåŒ¯å‡º

é›–ç„¶ Web ä»‹é¢ä¸»è¦ç”¨æ–¼æª¢è¦–ï¼Œä½†å¯ä»¥ï¼š

- å³éµä¿å­˜è…¦éƒ¨æ´»åŒ–åœ–
- è¤‡è£½æ–‡æœ¬å ±å‘Šå…§å®¹
- ä½¿ç”¨ç€è¦½å™¨çš„åˆ—å°åŠŸèƒ½ä¿å­˜å®Œæ•´å ±å‘Š

---

## å‘½ä»¤åˆ—æ“ä½œ

### ğŸ”§ å®Œæ•´åˆ†æç®¡é“

å°æ–¼æ‰¹æ¬¡è™•ç†æˆ–è‡ªå‹•åŒ–éœ€æ±‚ï¼Œå¯ä½¿ç”¨å‘½ä»¤åˆ—ç›´æ¥åŸ·è¡Œåˆ†æç®¡é“ï¼š

#### æ–¹æ³• 1: ä½¿ç”¨ LangGraph å·¥ä½œæµ

```bash
# ç›´æ¥åŸ·è¡Œ LangGraph ç®¡é“
python -m app.graph.workflow

# æˆ–è€…é€é Python è…³æœ¬è‡ªå®šç¾©è¼¸å…¥
python -c "
from app.graph.workflow import app
result = app.invoke({
    'subject_id': 'sub-01',
    'fmri_scan_path': 'data/raw/CN/sub-01/scan.nii.gz',
    'model_path': 'model/capsnet/best_capsnet_rnn.pth',
    'error_log': [],
    'trace_log': []
})
print('Analysis completed:', result.get('classification_result'))
"
```

#### æ–¹æ³• 2: ä½¿ç”¨èˆŠç‰ˆ Google ADK ç³»çµ±

```bash
# åŸ·è¡Œå®Œæ•´çš„å¤šæ™ºèƒ½é«”ç®¡é“
python -m agents.agent

# æˆ–ä½¿ç”¨å¾Œç«¯åŸ·è¡Œå™¨
python -m backend.backend_runner
```

### ğŸ§ª å–®æ­¥é©Ÿåˆ†æå‘½ä»¤

#### æ¨¡å‹è¨“ç·´

```bash
# è¨“ç·´ CapsNet-RNN æ¨¡å‹ï¼ˆä¸»è¦æ¨¡å‹ï¼‰
python -m scripts.capsnet.train

# è¨“ç·´ MCADNNet æ¨¡å‹ï¼ˆæ›¿ä»£æ¨¡å‹ï¼‰
python -m scripts.macadnnet.train

# æº–å‚™è¨“ç·´è³‡æ–™
python -m scripts.data_prepare
```

#### å–®ä¸€æ¨¡å‹æ¨ç†

```bash
# CapsNet-RNN æ¨ç†
python -m scripts.capsnet.infer

# MCADNNet æ¨ç†ï¼ŒæŒ‡å®šæ¨¡å‹å’Œè¼¸å…¥æª”æ¡ˆ
python -m scripts.macadnnet.inference \
    --model model/macadnnet/best_model.pth \
    --input data/raw/AD/sub-14/dswausub-098_S_6601_task-rest_bold.nii.gz
```

#### ç¾¤çµ„å±¤ç´šåˆ†æç®¡é“

é€™æ˜¯é€²è¡Œæ‰¹æ¬¡åˆ†æçš„å®Œæ•´æµç¨‹ï¼Œéœ€è¦æŒ‰é †åºåŸ·è¡Œï¼š

```bash
# 1. å°æ‰€æœ‰å—è©¦è€…ç”¢ç”Ÿæ´»åŒ–åœ–
python -m scripts.group.infer

# 2. å°‡æ´»åŒ–å¼µé‡è½‰æ›ç‚º NIfTI æ ¼å¼
python -m scripts.group.act_nii

# 3. é‡æ–°å–æ¨£æ´»åŒ–åœ–åˆ°æ¨™æº–åœ–è­œç©ºé–“
python -m scripts.group.resample

# 4. ç”¢ç”Ÿå®šé‡è…¦å€çµ±è¨ˆ
python -m scripts.group.brain_map

# 5. (å¯é¸) è¨ˆç®—ç¾¤çµ„å¹³å‡æ´»åŒ–åœ–
python -m scripts.group.get_avg_act

# 6. (å¯é¸) æª¢æŸ¥ç”Ÿæˆçš„åœ–è­œ
python -m scripts.group.check_map
```

### ğŸ•¸ï¸ çŸ¥è­˜åœ–è­œæ“ä½œ

```bash
# å»ºç½® Neo4j åœ–è³‡æ–™åº«
python -m tools.build_neo4j

# ç”¢ç”Ÿ Cypher æŸ¥è©¢
python -m tools.generate_cypher

# æ¸¬è©¦çŸ¥è­˜åœ–è­œé€£æ¥
python -c "from app.services.neo4j_connector import Neo4jConnector; client = Neo4jConnector(); print('Neo4j connected successfully!')"
```

### ğŸ§ª ç³»çµ±æ¸¬è©¦å’Œé©—è­‰

```bash
# æ¸¬è©¦æ´»åŒ–åœ–æ“·å–
python -m tests.check_act

# é©—è­‰è…¦å€æ˜ å°„
python -m tests.brain_region

# æª¢æŸ¥æ¨¡å‹è³‡è¨Š
python -m tests.model_info

# æ¸¬è©¦å€‹åˆ¥çµ„ä»¶
python -m tests.image_explain
python -m tests.vertex  # Google ADK æ•´åˆæ¸¬è©¦
```

### ğŸ“Š æ‰¹æ¬¡è™•ç†è…³æœ¬ç¯„ä¾‹

å‰µå»ºè‡ªå®šç¾©æ‰¹æ¬¡è™•ç†è…³æœ¬ï¼š

```python
# batch_analysis.py
from app.graph.workflow import app
import glob
import json

# å–å¾—æ‰€æœ‰å—è©¦è€…
subjects = glob.glob("data/raw/*/sub-*")
results = {}

for subject_path in subjects:
    subject_id = subject_path.split('/')[-1]
    nii_files = glob.glob(f"{subject_path}/*.nii.gz")
  
    if nii_files:
        print(f"Processing {subject_id}...")
    
        state = {
            "subject_id": subject_id,
            "fmri_scan_path": nii_files[0],
            "model_path": "model/capsnet/best_capsnet_rnn.pth",
            "error_log": [],
            "trace_log": []
        }
    
        try:
            result = app.invoke(state)
            results[subject_id] = {
                "classification": result.get("classification_result"),
                "activated_regions": len(result.get("activated_regions", [])),
                "status": "success"
            }
        except Exception as e:
            results[subject_id] = {"status": "error", "error": str(e)}

# ä¿å­˜çµæœ
with open("batch_results.json", "w") as f:
    json.dump(results, f, indent=2)

print("Batch processing completed. Results saved to batch_results.json")
```

åŸ·è¡Œæ‰¹æ¬¡è™•ç†ï¼š

```bash
python batch_analysis.py
```

---

## æ•…éšœæ’é™¤

### ğŸš¨ å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### 1. CUDA/GPU ç›¸é—œå•é¡Œ

**å•é¡Œ**: CUDA ä¸å¯ç”¨æˆ– GPU è¨˜æ†¶é«”ä¸è¶³

```bash
RuntimeError: CUDA out of memory
torch.cuda.is_available() returns False
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ CUDA å®‰è£
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# é‡æ–°å®‰è£ PyTorch (æ¨è–¦æ–¹æ³•)
python -m pip install light-the-torch
python -m light_the_torch install --upgrade torch torchaudio torchvision

# æˆ–ä½¿ç”¨ CPU ç‰ˆæœ¬ (è¼ƒæ…¢ä½†ç©©å®š)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

#### 2. Neo4j è³‡æ–™åº«é€£æ¥å•é¡Œ

**å•é¡Œ**: Neo4j é€£æ¥å¤±æ•—

```bash
ServiceUnavailable: Failed to establish connection to Neo4j database
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ Neo4j æœå‹™ç‹€æ…‹
sudo systemctl status neo4j
docker ps | grep neo4j

# é‡æ–°å•Ÿå‹• Neo4j
sudo systemctl restart neo4j
# æˆ– Docker
docker restart neo4j-fmri

# æª¢æŸ¥é€£æ¥åŸ å’Œé˜²ç«ç‰†
netstat -an | grep 7687
telnet localhost 7687

# é©—è­‰ .env æª”æ¡ˆé…ç½®
cat .env | grep NEO4J
```

#### 3. Google API é‡‘é‘°å•é¡Œ

**å•é¡Œ**: Google API èªè­‰å¤±æ•—

```bash
google.api_core.exceptions.Unauthenticated: Request is missing required authentication credential
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ API é‡‘é‘°è¨­å®š
echo $GOOGLE_API_KEY
grep GOOGLE_API_KEY .env

# é‡æ–°è¼‰å…¥ç’°å¢ƒè®Šæ•¸
source .env
export GOOGLE_API_KEY="your_actual_api_key"

# æ¸¬è©¦ API é€£æ¥
python -c "
import google.generativeai as genai
genai.configure(api_key='your_api_key')
print('API key is valid')
"
```

#### 4. æª”æ¡ˆè·¯å¾‘å’Œæ¬Šé™å•é¡Œ

**å•é¡Œ**: æ‰¾ä¸åˆ°æª”æ¡ˆæˆ–æ¬Šé™è¢«æ‹’

```bash
FileNotFoundError: No such file or directory
PermissionError: [Errno 13] Permission denied
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥æª”æ¡ˆå­˜åœ¨æ€§
ls -la data/raw/
ls -la model/capsnet/

# ä¿®æ­£æ¬Šé™
chmod -R 755 data/ model/ output/
chown -R $USER:$USER data/ model/ output/

# æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h

# å»ºç«‹ç¼ºå¤±ç›®éŒ„
mkdir -p data/raw/{AD,CN} model/{capsnet,macadnnet} output/{activations,brain_maps,visualizations}
```

#### 5. è¨˜æ†¶é«”ä¸è¶³å•é¡Œ

**å•é¡Œ**: ç³»çµ±è¨˜æ†¶é«”ä¸è¶³

```bash
MemoryError: Unable to allocate array
RuntimeError: [enforce fail at alloc_cpu.cpp] out of memory
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ç³»çµ±è¨˜æ†¶é«”ä½¿ç”¨
free -h
htop

# æ¸…ç† Python å¿«å–
pip cache purge
python -c "import torch; torch.cuda.empty_cache()"

# èª¿æ•´æ‰¹æ¬¡å¤§å°ï¼ˆä¿®æ”¹ç¨‹å¼ç¢¼ï¼‰
# åœ¨ç›¸é—œçš„ Python æª”æ¡ˆä¸­æ¸›å°‘ batch_size åƒæ•¸

# å¢åŠ äº¤æ›ç©ºé–“ï¼ˆè‡¨æ™‚è§£æ±ºï¼‰
sudo swapon --show
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

#### 6. Streamlit Web æ‡‰ç”¨å•é¡Œ

**å•é¡Œ**: Web æ‡‰ç”¨ç„¡æ³•å•Ÿå‹•æˆ–è¼‰å…¥ç·©æ…¢

```bash
streamlit run app.py
ValueError: Session state is corrupted
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æ¸…é™¤ Streamlit å¿«å–
streamlit cache clear

# é‡æ–°å•Ÿå‹•æ–°çš„ session
rm -rf ~/.streamlit/
streamlit run app.py

# æª¢æŸ¥é€£æ¥åŸ å ç”¨
lsof -i :8501
kill -9 <PID>

# æŒ‡å®šä¸åŒé€£æ¥åŸ 
streamlit run app.py --server.port 8502
```

### ğŸ” è¨ºæ–·å·¥å…·

#### ç³»çµ±å¥åº·æª¢æŸ¥è…³æœ¬

å‰µå»ºä¸€å€‹è‡ªå‹•è¨ºæ–·è…³æœ¬ï¼š

```bash
# å‰µå»º health_check.py
cat > health_check.py << 'EOF'
#!/usr/bin/env python3
import os
import sys
import torch
import subprocess
import requests
from pathlib import Path

def check_python_version():
    version = sys.version_info
    print(f"âœ… Python version: {version.major}.{version.minor}.{version.micro}")
    if version.major < 3 or version.minor < 11:
        print("âŒ Python 3.11+ is required")
        return False
    return True

def check_cuda():
    cuda_available = torch.cuda.is_available()
    print(f"{'âœ…' if cuda_available else 'âš ï¸'} CUDA available: {cuda_available}")
    if cuda_available:
        print(f"   GPU count: {torch.cuda.device_count()}")
        print(f"   GPU name: {torch.cuda.get_device_name(0)}")
    return True

def check_env_file():
    env_path = Path('.env')
    if env_path.exists():
        print("âœ… .env file found")
        with open(env_path) as f:
            content = f.read()
            required_vars = ['NEO4J_URI', 'NEO4J_USERNAME', 'NEO4J_PASSWORD', 'GOOGLE_API_KEY']
            for var in required_vars:
                if var in content:
                    print(f"   âœ… {var} is set")
                else:
                    print(f"   âŒ {var} is missing")
        return True
    else:
        print("âŒ .env file not found")
        return False

def check_neo4j():
    try:
        response = requests.get('http://localhost:7474', timeout=5)
        print(f"âœ… Neo4j web interface responding: {response.status_code}")
        return True
    except:
        print("âŒ Neo4j not accessible on localhost:7474")
        return False

def check_data_structure():
    required_dirs = [
        'data/raw/AD',
        'data/raw/CN', 
        'model/capsnet',
        'model/macadnnet',
        'output'
    ]
  
    all_good = True
    for dir_path in required_dirs:
        if Path(dir_path).exists():
            print(f"âœ… Directory exists: {dir_path}")
        else:
            print(f"âŒ Directory missing: {dir_path}")
            all_good = False
  
    return all_good

def main():
    print("ğŸ” Neuro-Compass System Health Check")
    print("="*40)
  
    checks = [
        check_python_version,
        check_cuda,
        check_env_file,
        check_neo4j,
        check_data_structure
    ]
  
    results = []
    for check in checks:
        try:
            result = check()
            results.append(result)
        except Exception as e:
            print(f"âŒ Error in {check.__name__}: {e}")
            results.append(False)
        print()
  
    if all(results):
        print("ğŸ‰ All checks passed! System is ready.")
    else:
        print("âš ï¸ Some issues found. Please address them before proceeding.")
  
    return all(results)

if __name__ == "__main__":
    sys.exit(0 if main() else 1)
EOF

# åŸ·è¡Œå¥åº·æª¢æŸ¥
python health_check.py
```

#### è©³ç´°æ—¥èªŒè¨˜éŒ„

å•Ÿç”¨è©³ç´°çš„æ—¥èªŒè¨˜éŒ„é€²è¡Œé™¤éŒ¯ï¼š

```bash
# è¨­å®šæ—¥èªŒç­‰ç´šç’°å¢ƒè®Šæ•¸
export PYTHONPATH="${PYTHONPATH}:."
export LOG_LEVEL=DEBUG

# åŸ·è¡Œå¸¶æœ‰è©³ç´°æ—¥èªŒçš„åˆ†æ
python -m app.graph.workflow 2>&1 | tee analysis.log

# æª¢æŸ¥æ—¥èªŒæª”æ¡ˆ
grep -i error analysis.log
grep -i warning analysis.log
```

---

## ç¶­è­·èˆ‡å‡ç´š

### ğŸ”„ å®šæœŸç¶­è­·ä»»å‹™

#### æ¯é€±ç¶­è­·

```bash
# æ¸…ç†æš«å­˜æª”æ¡ˆ
find output/ -name "*.tmp" -delete
find /tmp -name "*fmri*" -delete 2>/dev/null || true

# æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h

# æ›´æ–° Python å¥—ä»¶å®‰å…¨æ€§æ›´æ–°
pip list --outdated
poetry show --outdated

# æª¢æŸ¥ Neo4j è³‡æ–™åº«æ•ˆèƒ½
echo "CALL dbms.procedures() YIELD name WHERE name CONTAINS 'monitor'" | cypher-shell
```

#### æ¯æœˆç¶­è­·

```bash
# å®Œæ•´ç³»çµ±å‚™ä»½
tar -czf neuro_compass_backup_$(date +%Y%m%d).tar.gz \
    .env model/ graphql/ data/processed/

# æ¸…ç† Docker æ˜ åƒæª”ï¼ˆå¦‚ä½¿ç”¨ï¼‰
docker system prune -f

# æª¢æŸ¥ä¸¦æ›´æ–°ç›¸ä¾å¥—ä»¶
poetry update
pip install --upgrade pip
```

### ğŸ“¦ ç³»çµ±å‡ç´šæµç¨‹

#### å‡ç´šåˆ°æ–°ç‰ˆæœ¬

```bash
# 1. å‚™ä»½ç•¶å‰ç‰ˆæœ¬
cp -r . ../neuro-compass-backup-$(date +%Y%m%d)

# 2. å–å¾—æœ€æ–°ç¨‹å¼ç¢¼
git fetch origin
git checkout main
git pull origin main

# 3. æ›´æ–°ç›¸ä¾å¥—ä»¶
poetry install
poetry update

# 4. é·ç§»è³‡æ–™åº«ï¼ˆå¦‚éœ€è¦ï¼‰
python -m tools.migrate_neo4j

# 5. åŸ·è¡Œå‡ç´šæ¸¬è©¦
python -m tests.upgrade_test

# 6. é‡æ–°å•Ÿå‹•æœå‹™
sudo systemctl restart neo4j
pkill -f streamlit
```

#### é…ç½®æª”æ¡ˆé·ç§»

å¦‚æœ `.env` æª”æ¡ˆæ ¼å¼æœ‰è®Šæ›´ï¼š

```bash
# å‚™ä»½èˆŠé…ç½®
cp .env .env.backup

# æª¢æŸ¥æ–°çš„é…ç½®ç¯„æœ¬
cat .env.template

# åˆä½µé…ç½®ï¼ˆæ‰‹å‹•æˆ–ä½¿ç”¨å·¥å…·ï¼‰
python -c "
import os
from pathlib import Path

old_config = Path('.env.backup').read_text()
new_template = Path('.env.template').read_text()

# æå–èˆŠå€¼ä¸¦æ‡‰ç”¨åˆ°æ–°ç¯„æœ¬
# (å¯¦éš›å¯¦ç¾æœƒæ›´è¤‡é›œ)
print('Please manually merge .env.backup into .env using the new template')
"
```

### ğŸ¯ æ•ˆèƒ½å„ªåŒ–

#### Neo4j è³‡æ–™åº«å„ªåŒ–

```bash
# èª¿æ•´ Neo4j è¨­å®š
sudo nano /etc/neo4j/neo4j.conf

# é—œéµè¨­å®šï¼š
# server.memory.heap.initial_size=2G
# server.memory.heap.max_size=4G
# server.memory.pagecache.size=1G

# é‡å»ºç´¢å¼•
echo "CALL db.index.fulltext.createNodeIndex('entities', ['Entity'], ['name', 'type'])" | cypher-shell

# é‡æ–°å•Ÿå‹• Neo4j
sudo systemctl restart neo4j
```

#### Python è¨˜æ†¶é«”å„ªåŒ–

```python
# åœ¨åˆ†æè…³æœ¬ä¸­åŠ å…¥è¨˜æ†¶é«”å„ªåŒ–
import gc
import torch

def optimize_memory():
    """è¨˜æ†¶é«”å„ªåŒ–å‡½æ•¸"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
  
# åœ¨é—œéµä½ç½®å‘¼å«
optimize_memory()
```

### ğŸ” å®‰å…¨æ€§æ›´æ–°

#### å®šæœŸå®‰å…¨æª¢æŸ¥

```bash
# æª¢æŸ¥ Python å¥—ä»¶å®‰å…¨æ¼æ´
pip audit
poetry audit

# æ›´æ–°æœ‰å®‰å…¨æ¼æ´çš„å¥—ä»¶
pip install --upgrade vulnerable-package
poetry update vulnerable-package

# æª¢æŸ¥ Neo4j å®‰å…¨è¨­å®š
curl -u neo4j:password http://localhost:7474/db/manage/server/info
```

#### æ†‘è­‰è¼ªæ›

```bash
# æ›´æ–° API é‡‘é‘°ï¼ˆGoogle API ç¯„ä¾‹ï¼‰
# 1. åœ¨ Google Cloud Console ç”¢ç”Ÿæ–°é‡‘é‘°
# 2. æ›´æ–° .env æª”æ¡ˆ
sed -i 's/GOOGLE_API_KEY=old_key/GOOGLE_API_KEY=new_key/' .env

# 3. é‡æ–°å•Ÿå‹•ç›¸é—œæœå‹™
pkill -f streamlit
streamlit run app.py &

# æ›´æ–° Neo4j å¯†ç¢¼
echo "ALTER CURRENT USER SET PASSWORD FROM 'old_password' TO 'new_password'" | cypher-shell -u neo4j -p old_password
```

---

## é–‹ç™¼è€…æŒ‡å—

### ğŸ› ï¸ é–‹ç™¼ç’°å¢ƒè¨­ç½®

#### è¨­ç½®é–‹ç™¼ç’°å¢ƒ

```bash
# è¤‡è£½å°ˆæ¡ˆä¸¦åˆ‡æ›åˆ°é–‹ç™¼åˆ†æ”¯
git clone [repository-url]
cd semantic-KG
git checkout develop

# å®‰è£é–‹ç™¼ç›¸ä¾å¥—ä»¶
poetry install --with dev
poetry run pre-commit install

# è¨­ç½®é–‹ç™¼ç’°å¢ƒè®Šæ•¸
cp .env.template .env.dev
nano .env.dev  # ç·¨è¼¯é–‹ç™¼è¨­å®š
```

#### ç¨‹å¼ç¢¼å“è³ªå·¥å…·

```bash
# ç¨‹å¼ç¢¼æ ¼å¼åŒ–
poetry run black .
poetry run isort .

# éœæ…‹åˆ†æ
poetry run flake8 .
poetry run mypy .

# æ¸¬è©¦è¦†è“‹ç‡
poetry run pytest --cov=app tests/
poetry run coverage html  # ç”¢ç”Ÿ HTML å ±å‘Š
```

### ğŸ—ï¸ æ¶æ§‹è§£æ

#### LangGraph å·¥ä½œæµ

ç³»çµ±çš„æ ¸å¿ƒæ˜¯åŸºæ–¼ LangGraph çš„ 7 ç¯€é»åºåˆ—åŒ–ç®¡é“ï¼š

```python
# app/graph/workflow.py çµæ§‹è§£æ
from langgraph.graph import StateGraph, START, END
from .state import AgentState

# å»ºç«‹å·¥ä½œæµ
workflow = StateGraph(AgentState)

# 7 å€‹ä¸»è¦ç¯€é»
nodes = [
    ("inference", run_inference_and_classification),      # æ¨¡å‹æ¨ç†
    ("filtering", filter_layers_dynamically),             # å‹•æ…‹å±¤ç¯©é¸
    ("post_processing", run_post_processing),             # å¾Œè™•ç†
    ("entity_linker", link_entities),                     # å¯¦é«”é€£çµ
    ("knowledge_reasoner", enrich_with_knowledge_graph),  # çŸ¥è­˜æ¨ç†
    ("image_explainer", explain_image),                   # å½±åƒè§£é‡‹
    ("report_generator", generate_final_report)           # å ±å‘Šç”Ÿæˆ
]

# é †åºé€£æ¥æ‰€æœ‰ç¯€é»
for i, (name, func) in enumerate(nodes):
    workflow.add_node(name, func)
    if i == 0:
        workflow.add_edge(START, name)
    else:
        prev_name = nodes[i-1][0]
        workflow.add_edge(prev_name, name)
    if i == len(nodes) - 1:
        workflow.add_edge(name, END)
```

#### AgentState ç‹€æ…‹ç®¡ç†

ç‹€æ…‹ç‰©ä»¶åŒ…å«æ‰€æœ‰ä¸­é–“çµæœå’Œæœ€çµ‚è¼¸å‡ºï¼š

```python
# app/graph/state.py çµæ§‹è§£æ
class AgentState(TypedDict):
    # è¼¸å…¥è³‡æ–™
    subject_id: str                           # å—è©¦è€… ID
    fmri_scan_path: str                       # fMRI æª”æ¡ˆè·¯å¾‘
    model_path: Optional[str]                 # æ¨¡å‹æ¬Šé‡è·¯å¾‘
    model_name: Optional[str]                 # æ¨¡å‹åç¨±
  
    # ä¸­é–“è™•ç†çµæœ
    validated_layers: Optional[List[Dict]]    # é©—è­‰çš„æ¨¡å‹å±¤
    final_layers: Optional[List[Dict]]        # ç¯©é¸å¾Œçš„å±¤
    post_processing_results: Optional[List]   # å¾Œè™•ç†çµæœ
    clean_region_names: Optional[List[str]]   # æ¸…ç†çš„è…¦å€åç¨±
  
    # æœ€çµ‚è¼¸å‡º
    classification_result: Optional[str]      # AD/CN åˆ†é¡çµæœ
    activated_regions: Optional[List[BrainRegionInfo]]  # æ´»åŒ–è…¦å€
    visualization_paths: Optional[List[str]]  # è¦–è¦ºåŒ–åœ–ç‰‡è·¯å¾‘
    image_explanation: Optional[Dict]         # å½±åƒè§£é‡‹
    rag_summary: Optional[str]               # çŸ¥è­˜æ‘˜è¦
    generated_reports: Optional[Dict[str, str]]  # ä¸­è‹±æ–‡å ±å‘Š
  
    # ç³»çµ±æ—¥èªŒ
    error_log: List[str]                     # éŒ¯èª¤æ—¥èªŒ
    trace_log: List[str]                     # åŸ·è¡Œè¿½è¹¤
```

### ğŸ”Œ æ“´å±•é–‹ç™¼

#### æ–°å¢è‡ªå®šç¾©ç¯€é»

1. **å»ºç«‹æ–°ç¯€é»å‡½æ•¸**:

```python
# app/agents/custom_node.py
from app.graph.state import AgentState
from typing import Any, Dict

def custom_analysis_node(state: AgentState) -> Dict[str, Any]:
    """è‡ªå®šç¾©åˆ†æç¯€é»"""
  
    # å¾ç‹€æ…‹å–å¾—è¼¸å…¥
    subject_id = state["subject_id"]
    current_results = state.get("post_processing_results", [])
  
    # åŸ·è¡Œè‡ªå®šç¾©åˆ†æ
    custom_results = perform_custom_analysis(current_results)
  
    # æ›´æ–°ç‹€æ…‹
    state["trace_log"].append(f"Custom analysis completed for {subject_id}")
    state["custom_results"] = custom_results
  
    return state

def perform_custom_analysis(input_data):
    """å¯¦éš›çš„è‡ªå®šç¾©åˆ†æé‚è¼¯"""
    # å¯¦ç¾ä½ çš„åˆ†æé‚è¼¯
    pass
```

2. **æ•´åˆåˆ°å·¥ä½œæµ**:

```python
# ä¿®æ”¹ app/graph/workflow.py
from app.agents.custom_node import custom_analysis_node

# åŠ å…¥æ–°ç¯€é»
workflow.add_node("custom_analyzer", custom_analysis_node)

# èª¿æ•´é‚Šé€£æ¥
workflow.add_edge("post_processing", "custom_analyzer")
workflow.add_edge("custom_analyzer", "entity_linker")
```

#### æ–°å¢æ¨¡å‹æ”¯æ´

1. **å»ºç«‹æ¨¡å‹é…ç½®**:

```python
# app/core/fmri_processing/model_config.py æ“´å±•
class CustomModelConfig(ModelConfig):
    """è‡ªå®šç¾©æ¨¡å‹é…ç½®"""
  
    def __init__(self):
        super().__init__()
        self.model_name = "custom_model"
        self.layer_selection_strategy = "custom_strategy"
        self.target_layers = ["custom_layer_1", "custom_layer_2"]
  
    def validate_layers(self, model) -> List[Dict]:
        """é©—è­‰è‡ªå®šç¾©æ¨¡å‹çš„å±¤"""
        # å¯¦ç¾å±¤é©—è­‰é‚è¼¯
        pass
```

2. **è¨»å†Šåˆ°æ¨¡å‹å·¥å» **:

```python
# app/core/fmri_processing/model_factory.py
from .model_config import CustomModelConfig

class ModelFactory:
    @staticmethod
    def create_config(model_name: str):
        configs = {
            "capsnet": CapsNetConfig(),
            "mcadnnet": MCADNNetConfig(),
            "custom_model": CustomModelConfig()  # æ–°å¢
        }
        return configs.get(model_name, CapsNetConfig())
```

### ğŸ§ª æ¸¬è©¦é–‹ç™¼

#### å–®å…ƒæ¸¬è©¦

```python
# tests/test_workflow.py
import pytest
from app.graph.workflow import app
from app.graph.state import AgentState

class TestWorkflow:
    def test_inference_node(self):
        """æ¸¬è©¦æ¨ç†ç¯€é»"""
        initial_state = {
            "subject_id": "test_sub",
            "fmri_scan_path": "test_path.nii.gz",
            "model_path": "test_model.pth",
            "error_log": [],
            "trace_log": []
        }
    
        # æ¸¬è©¦å–®å€‹ç¯€é»
        from app.agents.inference import run_inference_and_classification
        result = run_inference_and_classification(initial_state)
    
        assert "classification_result" in result
        assert result["classification_result"] in ["AD", "CN"]
  
    def test_full_workflow(self):
        """æ¸¬è©¦å®Œæ•´å·¥ä½œæµ"""
        initial_state = {
            "subject_id": "test_sub",
            "fmri_scan_path": "data/test/test.nii.gz",
            "model_path": "model/test/test.pth",
            "error_log": [],
            "trace_log": []
        }
    
        result = app.invoke(initial_state)
    
        # é©—è­‰æ‰€æœ‰å¿…è¦æ¬„ä½å­˜åœ¨
        required_fields = [
            "classification_result",
            "activated_regions",
            "generated_reports"
        ]
    
        for field in required_fields:
            assert field in result
            assert result[field] is not None

# åŸ·è¡Œæ¸¬è©¦
# poetry run pytest tests/test_workflow.py -v
```

#### æ•´åˆæ¸¬è©¦

```python
# tests/test_integration.py
import pytest
import tempfile
from pathlib import Path

class TestIntegration:
    @pytest.fixture
    def temp_data_dir(self):
        """å»ºç«‹è‡¨æ™‚æ¸¬è©¦è³‡æ–™"""
        with tempfile.TemporaryDirectory() as temp_dir:
            # å»ºç«‹æ¸¬è©¦è³‡æ–™çµæ§‹
            test_dir = Path(temp_dir)
            (test_dir / "data/raw/CN/sub-test").mkdir(parents=True)
            (test_dir / "model/capsnet").mkdir(parents=True)
        
            yield test_dir
  
    def test_neo4j_integration(self):
        """æ¸¬è©¦ Neo4j æ•´åˆ"""
        from app.services.neo4j_connector import Neo4jConnector
    
        connector = Neo4jConnector()
        result = connector.test_connection()
        assert result is True
  
    def test_llm_integration(self):
        """æ¸¬è©¦ LLM æœå‹™æ•´åˆ"""
        from app.services.llm_provider import LLMProvider
    
        provider = LLMProvider()
        response = provider.generate_text("Test prompt")
        assert len(response) > 0
```

### ğŸ“Š æ•ˆèƒ½åˆ†æ

#### åˆ†æå·¥å…·ä½¿ç”¨

```python
# æ•ˆèƒ½åˆ†æè…³æœ¬
# performance_analysis.py
import time
import psutil
import torch
from app.graph.workflow import app

def measure_performance():
    """æ¸¬é‡ç³»çµ±æ•ˆèƒ½"""
  
    # è¨˜éŒ„ç³»çµ±ç‹€æ…‹
    cpu_percent = psutil.cpu_percent(interval=1)
    memory_info = psutil.virtual_memory()
    gpu_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
  
    print(f"åˆå§‹ CPU ä½¿ç”¨ç‡: {cpu_percent}%")
    print(f"åˆå§‹è¨˜æ†¶é«”ä½¿ç”¨: {memory_info.percent}%")
    print(f"åˆå§‹ GPU è¨˜æ†¶é«”: {gpu_memory / 1024**2:.2f} MB")
  
    # åŸ·è¡Œåˆ†æä¸¦æ¸¬é‡æ™‚é–“
    start_time = time.time()
  
    initial_state = {
        "subject_id": "perf_test",
        "fmri_scan_path": "data/raw/CN/sub-01/scan.nii.gz",
        "model_path": "model/capsnet/best_capsnet_rnn.pth",
        "error_log": [],
        "trace_log": []
    }
  
    result = app.invoke(initial_state)
  
    end_time = time.time()
  
    # è¨˜éŒ„æœ€çµ‚ç‹€æ…‹
    final_cpu = psutil.cpu_percent(interval=1)
    final_memory = psutil.virtual_memory()
    final_gpu_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
  
    print(f"\nåˆ†æå®Œæˆæ™‚é–“: {end_time - start_time:.2f} ç§’")
    print(f"æœ€çµ‚ CPU ä½¿ç”¨ç‡: {final_cpu}%")
    print(f"æœ€çµ‚è¨˜æ†¶é«”ä½¿ç”¨: {final_memory.percent}%")
    print(f"æœ€çµ‚ GPU è¨˜æ†¶é«”: {final_gpu_memory / 1024**2:.2f} MB")
    print(f"GPU è¨˜æ†¶é«”å¢åŠ : {(final_gpu_memory - gpu_memory) / 1024**2:.2f} MB")

if __name__ == "__main__":
    measure_performance()
```

#### ç“¶é ¸è­˜åˆ¥

```bash
# ä½¿ç”¨ Python profiler
python -m cProfile -o profile_output.prof -m app.graph.workflow

# åˆ†æçµæœ
python -c "
import pstats
p = pstats.Stats('profile_output.prof')
p.sort_stats('tottime').print_stats(20)
"

# ä½¿ç”¨ line_profilerï¼ˆéœ€å®‰è£ï¼‰
pip install line_profiler
kernprof -l -v your_script.py
```

---

## FAQ å¸¸è¦‹å•é¡Œ

### â“ ç³»çµ±ä½¿ç”¨ç›¸é—œ

**Q: åˆ†æä¸€å€‹å—è©¦è€…éœ€è¦å¤šé•·æ™‚é–“ï¼Ÿ**
A: é€šå¸¸éœ€è¦ 3-5 åˆ†é˜ï¼Œå…·é«”å–æ±ºæ–¼ï¼š

- ç¡¬é«”é…ç½®ï¼ˆGPU åŠ é€Ÿå¯å¤§å¹…ç¸®çŸ­æ™‚é–“ï¼‰
- fMRI è³‡æ–™å¤§å°
- é¸æ“‡çš„æ¨¡å‹è¤‡é›œåº¦
- Neo4j è³‡æ–™åº«éŸ¿æ‡‰é€Ÿåº¦

**Q: ç³»çµ±æ”¯æ´å“ªäº› fMRI è³‡æ–™æ ¼å¼ï¼Ÿ**
A: ç›®å‰æ”¯æ´ï¼š

- NIfTI æ ¼å¼ï¼ˆ.nii, .nii.gzï¼‰
- 4D fMRI è³‡æ–™ï¼ˆæ™‚é–“åºåˆ—ï¼‰
- ADNI è³‡æ–™é›†æ ¼å¼
- æ¨™æº– MNI ç©ºé–“è³‡æ–™

**Q: å¯ä»¥åŒæ™‚åˆ†æå¤šå€‹å—è©¦è€…å—ï¼Ÿ**
A: Web ä»‹é¢ä¸€æ¬¡åªèƒ½åˆ†æä¸€å€‹å—è©¦è€…ï¼Œä½†å¯ä½¿ç”¨å‘½ä»¤åˆ—é€²è¡Œæ‰¹æ¬¡è™•ç†ï¼š

```bash
python batch_analysis.py  # è‡ªå®šç¾©æ‰¹æ¬¡è…³æœ¬
```

**Q: å¦‚ä½•è§£é‡‹åˆ†æçµæœï¼Ÿ**
A: ç³»çµ±æä¾›å¤šå±¤æ¬¡è§£é‡‹ï¼š

1. **åˆ†é¡çµæœ**: ADï¼ˆé˜¿èŒ²æµ·é»˜ç—‡ï¼‰æˆ– CNï¼ˆèªçŸ¥æ­£å¸¸ï¼‰
2. **è…¦å€æ´»åŒ–åœ–**: é¡¯ç¤ºç•°å¸¸æ´»åŒ–å€åŸŸ
3. **çŸ¥è­˜åœ–è­œé—œè¯**: è§£é‡‹æ´»åŒ–å€åŸŸèˆ‡ç–¾ç—…çš„é—œä¿‚
4. **è‡¨åºŠå ±å‘Š**: ä¸­è‹±æ–‡è©³ç´°è§£é‡‹å’Œå»ºè­°

### â“ æŠ€è¡“å•é¡Œ

**Q: é‡åˆ° "CUDA out of memory" éŒ¯èª¤æ€éº¼è¾¦ï¼Ÿ**
A: è§£æ±ºæ­¥é©Ÿï¼š

1. æª¢æŸ¥ GPU è¨˜æ†¶é«”ä½¿ç”¨: `nvidia-smi`
2. é—œé–‰å…¶ä»–ä½¿ç”¨ GPU çš„ç¨‹å¼
3. é‡æ–°å•Ÿå‹• Python ç¨‹åº
4. å¦‚æœå•é¡ŒæŒçºŒï¼Œå¯ä½¿ç”¨ CPU ç‰ˆæœ¬ï¼ˆè¼ƒæ…¢ï¼‰

**Q: Neo4j é€£æ¥å¤±æ•—æ€éº¼è¾¦ï¼Ÿ**
A: æª¢æŸ¥é †åºï¼š

1. ç¢ºèª Neo4j æœå‹™é‹è¡Œ: `sudo systemctl status neo4j`
2. æª¢æŸ¥é€£æ¥åŸ : `netstat -an | grep 7687`
3. é©—è­‰ `.env` æª”æ¡ˆä¸­çš„èªè­‰è³‡è¨Š
4. æ¸¬è©¦é€£æ¥: `telnet localhost 7687`

**Q: ç‚ºä»€éº¼æˆ‘çš„åˆ†æçµæœä¸­åªæª¢æ¸¬åˆ°å¾ˆå°‘çš„è…¦å€ï¼Ÿ**
A: é€™å¯èƒ½æ˜¯ç”±æ–¼ï¼š

1. **æ¨¡å‹æ¬Šé‡å•é¡Œ**: ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„é è¨“ç·´æ¬Šé‡
2. **è³‡æ–™å“è³ª**: æª¢æŸ¥ fMRI è³‡æ–™çš„é è™•ç†å“è³ª
3. **åº§æ¨™ç³»çµ±**: æ–°ç‰ˆç³»çµ±å·²ä¿®æ­£åº§æ¨™æ˜ å°„å•é¡Œ
4. **é–¾å€¼è¨­å®š**: å¯èƒ½éœ€è¦èª¿æ•´æ´»åŒ–é–¾å€¼

**Q: ç³»çµ±å ±å‘Šçš„èªè¨€å¯ä»¥è‡ªå®šç¾©å—ï¼Ÿ**
A: ç›®å‰æ”¯æ´ä¸­è‹±æ–‡é›™èªå ±å‘Šã€‚å¦‚éœ€å…¶ä»–èªè¨€ï¼Œéœ€è¦ä¿®æ”¹ `app/agents/report_generator.py` ä¸­çš„æç¤ºè©ã€‚

### â“ å®‰è£å’Œé…ç½®

**Q: Python ç‰ˆæœ¬è¦æ±‚æ˜¯ä»€éº¼ï¼Ÿ**
A: éœ€è¦ Python 3.11 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆ< 3.14ï¼‰ã€‚æª¢æŸ¥ç‰ˆæœ¬ï¼š

```bash
python --version
python3 --version
```

**Q: å¯ä»¥åœ¨æ²’æœ‰ GPU çš„ç’°å¢ƒä¸‹é‹è¡Œå—ï¼Ÿ**
A: å¯ä»¥ï¼Œä½†æœƒè¼ƒæ…¢ã€‚ç³»çµ±æœƒè‡ªå‹•åµæ¸¬ç¡¬é«”ä¸¦é¸æ“‡é©ç•¶çš„åŸ·è¡Œæ–¹å¼ï¼š

- CUDA GPUï¼ˆæœ€å¿«ï¼‰
- Apple Silicon MPSï¼ˆMac M1/M2ï¼‰
- CPUï¼ˆæœ€æ…¢ä½†ç©©å®šï¼‰

**Q: Docker éƒ¨ç½²æ”¯æ´å—ï¼Ÿ**
A: ç›®å‰ä¸»è¦æ”¯æ´åŸç”Ÿå®‰è£ï¼Œä½†å¯ä»¥ä½¿ç”¨ Docker é‹è¡Œ Neo4jï¼š

```bash
docker run -d --name neo4j-fmri -p 7474:7474 -p 7687:7687 \
    -e NEO4J_AUTH=neo4j/password neo4j:5.28.2
```

**Q: åœ¨ Windows ä¸Šèƒ½é‹è¡Œå—ï¼Ÿ**
A: å¯ä»¥ï¼Œä½†å»ºè­°ï¼š

1. ä½¿ç”¨ WSL2ï¼ˆWindows Subsystem for Linuxï¼‰
2. æˆ–åœ¨ Windows ä¸Šç›´æ¥ä½¿ç”¨ Python 3.11+
3. ç¢ºä¿æ­£ç¢ºå®‰è£ CUDAï¼ˆå¦‚ä½¿ç”¨ GPUï¼‰

### â“ æ•ˆèƒ½å’Œå„ªåŒ–

**Q: å¦‚ä½•æå‡åˆ†æé€Ÿåº¦ï¼Ÿ**
A: å„ªåŒ–å»ºè­°ï¼š

1. **ä½¿ç”¨ GPU**: ç¢ºä¿ CUDA æ­£ç¢ºå®‰è£
2. **å¢åŠ è¨˜æ†¶é«”**: è‡³å°‘ 16GB RAM
3. **SSD å„²å­˜**: å°‡è³‡æ–™å’Œæ¨¡å‹å­˜æ–¼ SSD
4. **Neo4j å„ªåŒ–**: èª¿æ•´è¨˜æ†¶é«”è¨­å®š
5. **æ‰¹æ¬¡è™•ç†**: é¿å…é »ç¹çš„æ¨¡å‹è¼‰å…¥

**Q: ç³»çµ±è¨˜æ†¶é«”ä½¿ç”¨é‡å¾ˆå¤§æ€éº¼è¾¦ï¼Ÿ**
A: è¨˜æ†¶é«”ç®¡ç†ï¼š

```python
# åœ¨åˆ†æå¾Œæ¸…ç†è¨˜æ†¶é«”
import gc
import torch

gc.collect()
torch.cuda.empty_cache()
```

**Q: å¯ä»¥åœ¨é›²ç«¯é‹è¡Œå—ï¼Ÿ**
A: å¯ä»¥ï¼Œæ¨è–¦é…ç½®ï¼š

- **AWS**: p3.2xlarge æˆ– g4dn.xlarge
- **Google Cloud**: n1-highmem-4 + T4 GPU
- **Azure**: Standard_NC6s_v3

### â“ è³‡æ–™å’Œæ¨¡å‹

**Q: å¦‚ä½•å–å¾—é è¨“ç·´æ¨¡å‹æ¬Šé‡ï¼Ÿ**
A: å¾æä¾›çš„é›²ç«¯é€£çµä¸‹è¼‰ï¼š

```bash
# ä¸‹è¼‰ä¸¦æ”¾ç½®åˆ°æ­£ç¢ºç›®éŒ„
wget [model-download-url] -O model/capsnet/best_capsnet_rnn.pth
```

**Q: å¯ä»¥ä½¿ç”¨è‡ªå·±çš„ fMRI è³‡æ–™å—ï¼Ÿ**
A: å¯ä»¥ï¼Œä½†éœ€è¦ç¢ºä¿ï¼š

1. æ ¼å¼ç‚º NIfTIï¼ˆ.nii æˆ– .nii.gzï¼‰
2. åº§æ¨™ç³»çµ±ç‚º MNI ç©ºé–“
3. æª”æ¡ˆçµæ§‹ç¬¦åˆè¦æ±‚ï¼š
   ```
   data/raw/[condition]/[subject]/[filename].nii.gz
   ```

**Q: å¦‚ä½•è¨“ç·´è‡ªå®šç¾©æ¨¡å‹ï¼Ÿ**
A: ä½¿ç”¨æä¾›çš„è¨“ç·´è…³æœ¬ï¼š

```bash
# CapsNet-RNN è¨“ç·´
python -m scripts.capsnet.train

# MCADNNet è¨“ç·´  
python -m scripts.macadnnet.train
```

**Q: æ”¯æ´å…¶ä»–ç–¾ç—…çš„åˆ†æå—ï¼Ÿ**
A: ç›®å‰å°ˆæ³¨æ–¼é˜¿èŒ²æµ·é»˜ç—‡ï¼Œä½†æ¶æ§‹æ˜¯å¯æ“´å±•çš„ã€‚è¦æ”¯æ´å…¶ä»–ç–¾ç—…éœ€è¦ï¼š

1. ç›¸æ‡‰çš„è¨“ç·´è³‡æ–™
2. ç‰¹å®šç–¾ç—…çš„çŸ¥è­˜åœ–è­œ
3. ä¿®æ”¹åˆ†é¡æ¨™ç±¤å’Œå ±å‘Šæ¨¡æ¿

### â“ é–‹ç™¼å’Œå®¢è£½åŒ–

**Q: å¦‚ä½•æ–°å¢è‡ªå®šç¾©åˆ†ææ­¥é©Ÿï¼Ÿ**
A: åƒè€ƒé–‹ç™¼è€…æŒ‡å—ï¼Œä¸»è¦æ­¥é©Ÿï¼š

1. å»ºç«‹æ–°çš„ç¯€é»å‡½æ•¸
2. æ›´æ–° AgentState é¡å‹å®šç¾©
3. ä¿®æ”¹å·¥ä½œæµåœ–çµæ§‹
4. æ¸¬è©¦æ–°åŠŸèƒ½

**Q: å¯ä»¥æ•´åˆå…¶ä»– LLM æœå‹™å—ï¼Ÿ**
A: å¯ä»¥ï¼æ–°çš„æ¨¡çµ„åŒ–æ¶æ§‹è®“ LLM æ•´åˆæ›´å®¹æ˜“ï¼š

```python
# åœ¨ app/services/llm_providers/ ä¸­æ–°å¢ custom_provider.py
def handle_text(prompt: str, *, model: str, **kwargs) -> str:
    """è‡ªå®šç¾© LLM å‘¼å«å¯¦ç¾ã€‚"""
    # å¯¦ç¾ä½ çš„ LLM API å‘¼å«
    pass

def handle_image(prompt: str, *, image_path, model: str, **kwargs) -> str:
    """è‡ªå®šç¾©å¤šæ¨¡æ…‹å‘¼å«å¯¦ç¾ï¼ˆå¦‚æœæ”¯æ´ï¼‰ã€‚"""
    # å¯¦ç¾å¤šæ¨¡æ…‹åŠŸèƒ½
    pass
```

ç„¶å¾Œåœ¨ `__init__.py` ä¸­è¨»å†Š:
```python
from app.services.llm_providers import custom_provider

def llm_response(prompt, *, llm_provider, model=None, **kwargs):
    if llm_provider == "custom":
        return custom_provider.handle_text(prompt=prompt, model=model, **kwargs)
    # ... å…¶ä»–ä¾›æ‡‰å•†
```

**Q: å¦‚ä½•å®¢è£½åŒ–çŸ¥è­˜åœ–è­œï¼Ÿ**
A: ä¿®æ”¹ `tools/build_neo4j.py` å’Œç›¸é—œçš„åœ–è³‡æ–™æª”æ¡ˆï¼š

1. æº–å‚™æ–°çš„ç¯€é»å’Œé—œä¿‚è³‡æ–™
2. æ›´æ–° Cypher æŸ¥è©¢æ¨¡æ¿
3. é‡æ–°å»ºç½®åœ–è³‡æ–™åº«

**Q: ç³»çµ±æœ‰ API ä»‹é¢å—ï¼Ÿ**
A: ç›®å‰ä¸»è¦æä¾› Web ä»‹é¢å’Œå‘½ä»¤åˆ—å·¥å…·ã€‚å¦‚éœ€ APIï¼Œå¯ä»¥åŸºæ–¼ç¾æœ‰çš„ LangGraph å·¥ä½œæµåŒ…è£ FastAPIï¼š

```python
# api.py ç¯„ä¾‹
from fastapi import FastAPI
from pydantic import BaseModel
from app.graph.workflow import app as workflow_app

app = FastAPI()

class AnalysisRequest(BaseModel):
    subject_id: str
    fmri_scan_path: str
    model_path: str
    llm_provider: str = "gemini"  # å…è¨±é¸æ“‡ LLM ä¾›æ‡‰å•†

@app.post("/analyze")
async def analyze_fmri(request: AnalysisRequest):
    state = {
        "subject_id": request.subject_id,
        "fmri_scan_path": request.fmri_scan_path,
        "model_path": request.model_path,
        "llm_provider": request.llm_provider,
        "error_log": [],
        "trace_log": []
    }
    result = workflow_app.invoke(state)
    return result
```

---

é€™ä»½ä½¿ç”¨æ‰‹å†Šæ¶µè“‹äº† Neuro-Compass ç³»çµ±çš„æ‰€æœ‰ä¸»è¦åŠŸèƒ½å’Œä½¿ç”¨æ–¹å¼ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•å…¶ä»–å•é¡Œï¼Œè«‹åƒè€ƒç¨‹å¼ç¢¼è¨»è§£æˆ–è¯ç¹«é–‹ç™¼åœ˜éšŠã€‚ç³»çµ±æœƒæŒçºŒæ›´æ–°å’Œæ”¹é€²ï¼Œè«‹å®šæœŸæª¢æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬ç™¼å¸ƒã€‚
